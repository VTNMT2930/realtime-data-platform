# üîç H∆∞·ªõng d·∫´n Debug Producer Logs

## T·ªïng quan

T√†i li·ªáu n√†y gi√∫p b·∫°n debug v√† ki·ªÉm tra xem Producer c√≥ t·∫°o log summary khi g·ª≠i message th√†nh c√¥ng t·ªõi Kafka hay kh√¥ng.

## V·∫•n ƒë·ªÅ ƒë√£ gi·∫£i quy·∫øt

- ‚úÖ Th√™m endpoint API ƒë·ªÉ l·∫•y log chi ti·∫øt theo ID
- ‚úÖ Th√™m logging chi ti·∫øt trong Producer service
- ‚úÖ T·∫°o Debug View ƒë·ªÉ ki·ªÉm tra logs d·ªÖ d√†ng
- ‚úÖ C·∫£i thi·ªán message summary khi upload CSV file

## C√°ch s·ª≠ d·ª•ng Debug View

### 1. Truy c·∫≠p Debug View

M·ªü tr√¨nh duy·ªát v√† truy c·∫≠p:

```
http://localhost:5173/#/debug-logs
```

Ho·∫∑c click v√†o menu **"Debug Logs"** tr√™n sidebar.

### 2. Xem t·∫•t c·∫£ logs

Debug view s·∫Ω hi·ªÉn th·ªã t·∫•t c·∫£ logs v·ªõi c√°c th√¥ng tin:

- **ID**: Log ID (UUID)
- **Type**: SINGLE ho·∫∑c FILE
- **Status**: PENDING, PROCESSING, COMPLETED, FAILED
- **Topic**: Kafka topic ƒë√£ g·ª≠i
- **File Name**: T√™n file g·ªëc (n·∫øu l√† FILE type)
- **Created**: Th·ªùi gian t·∫°o log

### 3. T√¨m ki·∫øm log theo ID

1. Copy Log ID t·ª´ b·∫£ng ho·∫∑c t·ª´ API response
2. Paste v√†o √¥ "Nh·∫≠p Log ID..."
3. Click "T√¨m ki·∫øm" ho·∫∑c nh·∫•n Enter

K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã:

- Chi ti·∫øt ƒë·∫ßy ƒë·ªß c·ªßa log
- Data ƒë√£ ƒë∆∞·ª£c parse (JSON format)
- Error message (n·∫øu c√≥)

### 4. Filter logs

S·ª≠ d·ª•ng dropdown ƒë·ªÉ filter:

- **T·∫•t c·∫£ lo·∫°i**: Hi·ªÉn th·ªã t·∫•t c·∫£
- **Single**: Ch·ªâ hi·ªÉn th·ªã single messages
- **File**: Ch·ªâ hi·ªÉn th·ªã file uploads

## Ki·ªÉm tra Log Summary khi Upload CSV

### B∆∞·ªõc 1: Upload file CSV

1. Truy c·∫≠p Configuration > Topics
2. Click v√†o m·ªôt topic
3. Click "Produce Message" > Tab "Upload File"
4. Ch·ªçn file CSV v√† upload

### B∆∞·ªõc 2: Xem logs trong terminal

Producer terminal s·∫Ω hi·ªÉn th·ªã:

```bash
Controller: ƒêang t·∫°o log cho file: test.csv Topic: upfile
Controller: ‚úÖ ƒê√£ t·∫°o LOG SUMMARY ban ƒë·∫ßu (ID: abc-123-def)
Controller: Th√™m job v√†o queue v·ªõi logId: abc-123-def, Topic: upfile

[Worker] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: ./uploads/... (Log ID: abc-123-def, Topic: upfile)
[Worker] G·ª≠i batch 1: 100 records t·ªõi topic "upfile" (Log ID: abc-123-def)...
[Worker] G·ª≠i batch 2: 100 records t·ªõi topic "upfile" (Log ID: abc-123-def)...
...
[Worker] ƒê√£ x·ª≠ l√Ω V√Ä G·ª¨I KAFKA xong file CSV t·ªõi topic "upfile": ... - Total: 250 records in 3 batches
[Worker] ‚úÖ ƒê√É C·∫¨P NH·∫¨T LOG SUMMARY (ID: abc-123-def): {
  totalRecords: 250,
  totalBatches: 3,
  message: "ƒê√£ g·ª≠i th√†nh c√¥ng 250 records trong 3 batches t·ªõi Kafka topic: upfile",
  topic: "upfile"
}
```

### B∆∞·ªõc 3: Ki·ªÉm tra trong Debug View

1. Truy c·∫≠p Debug View
2. Copy Log ID t·ª´ terminal (v√≠ d·ª•: `abc-123-def`)
3. T√¨m ki·∫øm log theo ID
4. X√°c nh·∫≠n th√¥ng tin:
   - Status = COMPLETED
   - Data ch·ª©a: totalRecords, totalBatches, message

## API Endpoints m·ªõi

### 1. L·∫•y log theo ID

```http
GET /api/producers/logs/:id
```

**Response:**

```json
{
  "success": true,
  "data": {
    "id": "abc-123-def",
    "type": "FILE",
    "status": "COMPLETED",
    "topic": "upfile",
    "originalFileName": "test.csv",
    "createdAt": "2025-11-02T10:00:00.000Z",
    "updatedAt": "2025-11-02T10:00:05.000Z",
    "data": "{\"totalRecords\":250,\"totalBatches\":3,...}",
    "parsedData": {
      "totalRecords": 250,
      "totalBatches": 3,
      "message": "ƒê√£ g·ª≠i th√†nh c√¥ng 250 records trong 3 batches t·ªõi Kafka topic: upfile",
      "topic": "upfile"
    }
  }
}
```

### 2. L·∫•y danh s√°ch logs (ƒë√£ c√≥, c·∫£i ti·∫øn)

```http
GET /api/producers/logs?page=1&limit=50&type=FILE&topic=upfile
```

## Troubleshooting

### V·∫•n ƒë·ªÅ: Kh√¥ng th·∫•y log summary

**Nguy√™n nh√¢n c√≥ th·ªÉ:**

1. Worker ch∆∞a x·ª≠ l√Ω xong file
2. Log ID kh√¥ng ƒë√∫ng
3. Database connection issue

**C√°ch ki·ªÉm tra:**

1. Xem terminal logs c·ªßa Producer
2. Ki·ªÉm tra status c·ªßa log (c√≥ th·ªÉ c√≤n PROCESSING)
3. ƒê·ª£i v√†i gi√¢y v√† refresh l·∫°i

### V·∫•n ƒë·ªÅ: Data field l√† null ho·∫∑c r·ªóng

**Nguy√™n nh√¢n:**

- L·ªói khi parse CSV
- File upload b·ªã corrupt

**C√°ch ki·ªÉm tra:**

1. Xem `errorMessage` field
2. Check terminal logs ƒë·ªÉ xem l·ªói chi ti·∫øt

### V·∫•n ƒë·ªÅ: Frontend kh√¥ng hi·ªÉn th·ªã logs

**Nguy√™n nh√¢n:**

- API endpoint kh√¥ng tr·∫£ v·ªÅ ƒë√∫ng format
- CORS issue
- Network error

**C√°ch ki·ªÉm tra:**

1. M·ªü DevTools > Network tab
2. Xem API response
3. Check console logs

## L∆∞u √Ω quan tr·ªçng

### Log Summary vs Batch Logs

- **Log Summary**: Log ch√≠nh c·ªßa file upload, ch·ª©a t·ªïng h·ª£p (totalRecords, totalBatches)

  - `originalFileName`: T√™n file g·ªëc (v√≠ d·ª•: "test.csv")
  - `type`: FILE
  - `data`: JSON v·ªõi summary info

- **Batch Logs**: Logs cho t·ª´ng batch ri√™ng l·∫ª (kh√¥ng hi·ªÉn th·ªã trong file uploads)
  - `originalFileName`: "Batch 1", "Batch 2", etc.
  - `type`: FILE
  - `data`: Array c√°c records trong batch

### Status Flow

1. **PENDING**: Log v·ª´a ƒë∆∞·ª£c t·∫°o, ƒëang ch·ªù x·ª≠ l√Ω
2. **PROCESSING**: Worker ƒëang x·ª≠ l√Ω file
3. **COMPLETED**: ƒê√£ g·ª≠i th√†nh c√¥ng t·∫•t c·∫£ batches t·ªõi Kafka
4. **FAILED**: C√≥ l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω

## Testing Script

ƒê·ªÉ test nhanh, b·∫°n c√≥ th·ªÉ d√πng curl:

```bash
# L·∫•y t·∫•t c·∫£ logs
curl http://localhost:3000/api/producers/logs

# L·∫•y log theo ID
curl http://localhost:3000/api/producers/logs/YOUR_LOG_ID

# L·∫•y file uploads only
curl http://localhost:3000/api/producers/uploads
```

## K·∫øt lu·∫≠n

V·ªõi c√°c c√¥ng c·ª• debug m·ªõi n√†y, b·∫°n c√≥ th·ªÉ:

- ‚úÖ X√°c nh·∫≠n Producer ƒë√£ t·∫°o log summary
- ‚úÖ Ki·ªÉm tra chi ti·∫øt data trong log
- ‚úÖ Debug c√°c v·∫•n ƒë·ªÅ v·ªÅ upload file
- ‚úÖ Trace logs t·ª´ Producer sang Consumer

N·∫øu v·∫´n g·∫∑p v·∫•n ƒë·ªÅ, h√£y:

1. Check terminal logs c·ªßa c·∫£ Producer v√† Consumer
2. Xem database tr·ª±c ti·∫øp
3. Ki·ªÉm tra Kafka broker logs
